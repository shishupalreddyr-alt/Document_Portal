import os
from dotenv import load_dotenv
from langchain.memory import ChatMessageHistory
from langchain_community.vectorstores import FAISS
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.runnables.base import RunnableMap
from langchain.chains.retrieval import create_retrieval_chain
from langchain.chains.history_aware_retriever import create_history_aware_retriever
from langchain.chains.combine_documents import create_stuff_documents_chain
from utils.model_loader import ModelLoader
from exception.custom_exception import DocumentPortalException
from logger.custom_logger import CustomLogger
from promptengg.promptlibrary import PROMPT_REGISTRY
from model.models import *

class ConversationalRAG:
    def __init__(self, session_id: str, retriever):
        try:
            # Load environment variables
            load_dotenv()
            
            self.log = CustomLogger().get_logger(__name__)
            self.session_id = session_id
            self.retriever = retriever
            self.loader = ModelLoader()
            
            # Load LLM
            self.llm = self.loader.load_llm()
            
            # Load prompts
            self.contextualize_prompt = PROMPT_REGISTRY[PromptType.CONTEXTUALIZE_QUESTION.value]
            self.qa_prompt = PROMPT_REGISTRY[PromptType.CONTEXT_QA.value]
            
            # History-aware retriever
            self.history_aware_retriever = create_history_aware_retriever(
                self.llm, self.retriever, self.contextualize_prompt
            )
            self.log.info("Created history-aware retriever", session_id=session_id)
            
            # QA chain
            self.qa_chain = create_stuff_documents_chain(self.llm, self.qa_prompt)
            
            # RAG chain
            self.rag_chain = create_retrieval_chain(self.history_aware_retriever, self.qa_chain)
            
            # Session message store
            self.store = {}
            self.log.info("Initialized and created RAG chain", session_id=session_id)
            
            # Runnable with history â€” FIX: input_message_key must match inner chain key ("query")
            self.chain = RunnableWithMessageHistory(
                RunnableMap({"input":self.rag_chain}),
                self._get_session_history,
                input_message_key="input",          
                history_message_keys=["chat_history"],
                output_message_key="answer"
            )
            self.log.info("RunnableWithMessageHistory created.", session_id=self.session_id)

        except Exception as e:
            self.log.error(f"Error initializing ConversationalRAG: {e}")
            raise DocumentPortalException(e)

    def _get_session_history(self):
        try:
            # Always return a ChatMessageHistory for this session
            if self.session_id not in self.store:
                self.store[self.session_id] = ChatMessageHistory()
            return self.store[self.session_id]
        except Exception as e:
            self.log.error(f"Error getting session history: {e}")
            raise DocumentPortalException(e)

    def load_retriever_from_faiss(self, index_path: str):
        try:
            embeddings = self.loader.load_embeddings()
            if not os.path.isdir(index_path):
                raise ValueError(f"FAISS index path does not exist: {index_path}")
            vector_store = FAISS.load_local(index_path, embeddings)
            self.log.info("FAISS retriever loaded successfully.", index_path=index_path, session_id=self.session_id)
            return vector_store.as_retriever(search_type="similarity", search_kwargs={"k": 5})
        except Exception as e:
            self.log.error(f"Error loading retriever from FAISS: {e}")
            raise DocumentPortalException(e)

    def invoke(self, user_input: str) -> str:
        try:
            # MUST pass dict with key matching input_message_key
            response = self.chain.invoke(
                {"input": user_input},                
                config={"configurable": {"session_id": self.session_id}}
            )
            answer = response.get("answer", "No answer")
            if not answer:
                self.log.warning("No answer generated by the RAG chain.", session_id=self.session_id)
            self.log.info(
                "RAG Chain invoked successfully",
                session_id=self.session_id,
                user_input=user_input,
                answer=answer
            )
            return answer
        except Exception as e:
            self.log.error(f"Error invoking ConversationalRAG: {e}")
            raise DocumentPortalException(e)